{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigQuery-Lite: DuckDB Analytics Engine\n",
    "\n",
    "This notebook demonstrates BigQuery-like functionality using DuckDB for embedded analytics.\n",
    "We'll explore:\n",
    "- Loading and querying Parquet files\n",
    "- Query execution plans\n",
    "- Custom UDFs (User Defined Functions)\n",
    "- Performance analysis and optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize DuckDB Connection and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DuckDB connection (in-memory for demonstration)\n",
    "conn = duckdb.connect(':memory:')\n",
    "\n",
    "# Enable query profiling\n",
    "conn.execute(\"PRAGMA enable_profiling\")\n",
    "conn.execute(\"PRAGMA profiling_mode = 'detailed'\")\n",
    "\n",
    "print(\"DuckDB version:\", duckdb.__version__)\n",
    "print(\"Connection established successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NYC taxi data from Parquet\n",
    "data_path = '../data/nyc_taxi.parquet'\n",
    "\n",
    "# Create a view from the Parquet file\n",
    "conn.execute(f\"CREATE VIEW nyc_taxi AS SELECT * FROM read_parquet('{data_path}')\")\n",
    "\n",
    "# Get basic info about the dataset\n",
    "result = conn.execute(\"SELECT COUNT(*) as total_rows FROM nyc_taxi\").fetchone()\n",
    "print(f\"Total rows in dataset: {result[0]:,}\")\n",
    "\n",
    "# Show schema\n",
    "schema_info = conn.execute(\"DESCRIBE nyc_taxi\").fetchdf()\n",
    "print(\"\\nDataset Schema:\")\n",
    "print(schema_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Query Exploration with Execution Plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample query: Average fare by payment type\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    payment_type,\n",
    "    COUNT(*) as trip_count,\n",
    "    AVG(fare_amount) as avg_fare,\n",
    "    AVG(trip_distance) as avg_distance,\n",
    "    AVG(total_amount) as avg_total\n",
    "FROM nyc_taxi \n",
    "WHERE fare_amount > 0 AND trip_distance > 0\n",
    "GROUP BY payment_type\n",
    "ORDER BY trip_count DESC\n",
    "\"\"\"\n",
    "\n",
    "# Execute and time the query\n",
    "start_time = time.time()\n",
    "result = conn.execute(query).fetchdf()\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Query executed in {execution_time:.4f} seconds\")\n",
    "print(\"\\nResults:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show query execution plan (BigQuery-like EXPLAIN)\n",
    "explain_query = f\"EXPLAIN ANALYZE {query}\"\n",
    "plan_result = conn.execute(explain_query).fetchdf()\n",
    "\n",
    "print(\"Query Execution Plan:\")\n",
    "print(\"=\" * 50)\n",
    "for row in plan_result.itertuples():\n",
    "    print(row.explain_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Advanced Analytics - Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series analysis: Daily trip patterns\n",
    "time_series_query = \"\"\"\n",
    "SELECT \n",
    "    DATE(tpep_pickup_datetime) as pickup_date,\n",
    "    EXTRACT(hour FROM tpep_pickup_datetime) as pickup_hour,\n",
    "    COUNT(*) as trip_count,\n",
    "    AVG(fare_amount) as avg_fare,\n",
    "    SUM(passenger_count) as total_passengers\n",
    "FROM nyc_taxi \n",
    "WHERE tpep_pickup_datetime IS NOT NULL\n",
    "GROUP BY pickup_date, pickup_hour\n",
    "ORDER BY pickup_date, pickup_hour\n",
    "\"\"\"\n",
    "\n",
    "time_series_data = conn.execute(time_series_query).fetchdf()\n",
    "print(f\"Time series data shape: {time_series_data.shape}\")\n",
    "print(time_series_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize hourly trip patterns\n",
    "hourly_trips = time_series_data.groupby('pickup_hour')['trip_count'].sum().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(hourly_trips['pickup_hour'], hourly_trips['trip_count'])\n",
    "plt.title('NYC Taxi Trips by Hour of Day')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Total Trip Count')\n",
    "plt.xticks(range(0, 24))\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Custom User Defined Functions (UDFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Python UDFs\n",
    "\n",
    "def calculate_tip_percentage(fare_amount, tip_amount):\n",
    "    \"\"\"Calculate tip percentage\"\"\"\n",
    "    if fare_amount <= 0:\n",
    "        return 0.0\n",
    "    return (tip_amount / fare_amount) * 100\n",
    "\n",
    "def categorize_trip_distance(distance):\n",
    "    \"\"\"Categorize trip distance\"\"\"\n",
    "    if distance <= 1.0:\n",
    "        return 'Short'\n",
    "    elif distance <= 5.0:\n",
    "        return 'Medium'\n",
    "    elif distance <= 15.0:\n",
    "        return 'Long'\n",
    "    else:\n",
    "        return 'Very Long'\n",
    "\n",
    "def calculate_speed_mph(distance, pickup_time, dropoff_time):\n",
    "    \"\"\"Calculate average speed in mph\"\"\"\n",
    "    if pickup_time is None or dropoff_time is None:\n",
    "        return 0.0\n",
    "    \n",
    "    duration_seconds = (dropoff_time - pickup_time).total_seconds()\n",
    "    if duration_seconds <= 0:\n",
    "        return 0.0\n",
    "    \n",
    "    duration_hours = duration_seconds / 3600\n",
    "    return distance / duration_hours if duration_hours > 0 else 0.0\n",
    "\n",
    "# Register UDFs with DuckDB\n",
    "conn.create_function('tip_percentage', calculate_tip_percentage)\n",
    "conn.create_function('trip_category', categorize_trip_distance)\n",
    "conn.create_function('avg_speed_mph', calculate_speed_mph)\n",
    "\n",
    "print(\"Custom UDFs registered successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use custom UDFs in queries\n",
    "udf_query = \"\"\"\n",
    "SELECT \n",
    "    trip_category(trip_distance) as distance_category,\n",
    "    COUNT(*) as trip_count,\n",
    "    AVG(tip_percentage(fare_amount, tip_amount)) as avg_tip_pct,\n",
    "    AVG(avg_speed_mph(trip_distance, tpep_pickup_datetime, tpep_dropoff_datetime)) as avg_speed\n",
    "FROM nyc_taxi \n",
    "WHERE \n",
    "    fare_amount > 0 \n",
    "    AND tip_amount >= 0 \n",
    "    AND trip_distance > 0\n",
    "    AND tpep_pickup_datetime IS NOT NULL \n",
    "    AND tpep_dropoff_datetime IS NOT NULL\n",
    "GROUP BY distance_category\n",
    "ORDER BY trip_count DESC\n",
    "\"\"\"\n",
    "\n",
    "udf_results = conn.execute(udf_query).fetchdf()\n",
    "print(\"Results using custom UDFs:\")\n",
    "print(udf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance Testing and Resource Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison of different query approaches\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "def monitor_query_performance(query, description):\n",
    "    \"\"\"Monitor query performance including memory usage\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    \n",
    "    # Before execution\n",
    "    mem_before = process.memory_info().rss / 1024 / 1024  # MB\n",
    "    \n",
    "    # Execute query\n",
    "    start_time = time.time()\n",
    "    result = conn.execute(query).fetchdf()\n",
    "    execution_time = time.time() - start_time\n",
    "    \n",
    "    # After execution\n",
    "    mem_after = process.memory_info().rss / 1024 / 1024  # MB\n",
    "    \n",
    "    print(f\"\\n{description}:\")\n",
    "    print(f\"  Execution time: {execution_time:.4f} seconds\")\n",
    "    print(f\"  Memory usage: {mem_after - mem_before:.2f} MB increase\")\n",
    "    print(f\"  Result rows: {len(result):,}\")\n",
    "    \n",
    "    return result, execution_time\n",
    "\n",
    "# Test different aggregation approaches\n",
    "simple_agg = \"SELECT COUNT(*), AVG(fare_amount) FROM nyc_taxi\"\n",
    "complex_agg = \"\"\"\n",
    "SELECT \n",
    "    DATE(tpep_pickup_datetime) as date,\n",
    "    payment_type,\n",
    "    trip_category(trip_distance) as distance_cat,\n",
    "    COUNT(*) as trips,\n",
    "    AVG(fare_amount) as avg_fare,\n",
    "    STDDEV(fare_amount) as stddev_fare,\n",
    "    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY fare_amount) as median_fare\n",
    "FROM nyc_taxi \n",
    "WHERE fare_amount > 0\n",
    "GROUP BY date, payment_type, distance_cat\n",
    "ORDER BY date, trips DESC\n",
    "\"\"\"\n",
    "\n",
    "# Run performance tests\n",
    "simple_result, simple_time = monitor_query_performance(simple_agg, \"Simple Aggregation\")\n",
    "complex_result, complex_time = monitor_query_performance(complex_agg, \"Complex Aggregation with UDF\")\n",
    "\n",
    "print(f\"\\nPerformance Summary:\")\n",
    "print(f\"Complex query is {complex_time/simple_time:.1f}x slower than simple query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. BigQuery-like Features: Window Functions and Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced analytics with window functions\n",
    "window_query = \"\"\"\n",
    "WITH daily_stats AS (\n",
    "    SELECT \n",
    "        DATE(tpep_pickup_datetime) as pickup_date,\n",
    "        COUNT(*) as daily_trips,\n",
    "        SUM(fare_amount) as daily_revenue,\n",
    "        AVG(fare_amount) as avg_fare\n",
    "    FROM nyc_taxi \n",
    "    WHERE tpep_pickup_datetime IS NOT NULL AND fare_amount > 0\n",
    "    GROUP BY pickup_date\n",
    ")\n",
    "SELECT \n",
    "    pickup_date,\n",
    "    daily_trips,\n",
    "    daily_revenue,\n",
    "    avg_fare,\n",
    "    -- Window functions for trend analysis\n",
    "    LAG(daily_trips, 1) OVER (ORDER BY pickup_date) as prev_day_trips,\n",
    "    daily_trips - LAG(daily_trips, 1) OVER (ORDER BY pickup_date) as trip_change,\n",
    "    AVG(daily_trips) OVER (ORDER BY pickup_date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) as weekly_avg_trips,\n",
    "    ROW_NUMBER() OVER (ORDER BY daily_revenue DESC) as revenue_rank\n",
    "FROM daily_stats\n",
    "ORDER BY pickup_date\n",
    "\"\"\"\n",
    "\n",
    "window_results = conn.execute(window_query).fetchdf()\n",
    "print(\"Window function analysis:\")\n",
    "print(window_results.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Query Optimization and Indexing Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate BigQuery-like table partitioning\n",
    "# Create a partitioned view by date\n",
    "partition_setup = \"\"\"\n",
    "CREATE OR REPLACE VIEW nyc_taxi_partitioned AS \n",
    "SELECT \n",
    "    *,\n",
    "    DATE(tpep_pickup_datetime) as partition_date,\n",
    "    EXTRACT(year FROM tpep_pickup_datetime) as partition_year,\n",
    "    EXTRACT(month FROM tpep_pickup_datetime) as partition_month\n",
    "FROM nyc_taxi\n",
    "WHERE tpep_pickup_datetime IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "conn.execute(partition_setup)\n",
    "\n",
    "# Test partition pruning effect\n",
    "partition_query = \"\"\"\n",
    "SELECT \n",
    "    partition_date,\n",
    "    COUNT(*) as trips,\n",
    "    AVG(fare_amount) as avg_fare\n",
    "FROM nyc_taxi_partitioned \n",
    "WHERE partition_date BETWEEN '2023-01-01' AND '2023-01-07'\n",
    "AND fare_amount > 0\n",
    "GROUP BY partition_date\n",
    "ORDER BY partition_date\n",
    "\"\"\"\n",
    "\n",
    "partition_result, partition_time = monitor_query_performance(\n",
    "    partition_query, \n",
    "    \"Partitioned Query (7 days)\"\n",
    ")\n",
    "\n",
    "print(\"\\nPartitioned query results:\")\n",
    "print(partition_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Export and Integration Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to different formats (BigQuery-like EXPORT)\n",
    "export_query = \"\"\"\n",
    "SELECT \n",
    "    payment_type,\n",
    "    trip_category(trip_distance) as distance_category,\n",
    "    COUNT(*) as trip_count,\n",
    "    AVG(fare_amount) as avg_fare,\n",
    "    AVG(tip_percentage(fare_amount, tip_amount)) as avg_tip_pct\n",
    "FROM nyc_taxi \n",
    "WHERE fare_amount > 0 AND tip_amount >= 0\n",
    "GROUP BY payment_type, distance_category\n",
    "ORDER BY payment_type, trip_count DESC\n",
    "\"\"\"\n",
    "\n",
    "export_data = conn.execute(export_query).fetchdf()\n",
    "\n",
    "# Export to CSV\n",
    "conn.execute(\"\"\"\n",
    "COPY (\n",
    "    SELECT \n",
    "        payment_type,\n",
    "        trip_category(trip_distance) as distance_category,\n",
    "        COUNT(*) as trip_count,\n",
    "        AVG(fare_amount) as avg_fare,\n",
    "        AVG(tip_percentage(fare_amount, tip_amount)) as avg_tip_pct\n",
    "    FROM nyc_taxi \n",
    "    WHERE fare_amount > 0 AND tip_amount >= 0\n",
    "    GROUP BY payment_type, distance_category\n",
    ") TO '../data/trip_summary.csv' WITH (HEADER 1, DELIMITER ',')\n",
    "\"\"\")\n",
    "\n",
    "# Export to Parquet\n",
    "conn.execute(\"\"\"\n",
    "COPY (\n",
    "    SELECT * FROM nyc_taxi WHERE fare_amount > 0 LIMIT 10000\n",
    ") TO '../data/sample_trips.parquet' (FORMAT PARQUET)\n",
    "\"\"\")\n",
    "\n",
    "print(\"Data exported successfully:\")\n",
    "print(\"- ../data/trip_summary.csv\")\n",
    "print(\"- ../data/sample_trips.parquet\")\n",
    "print(f\"\\nSummary data shape: {export_data.shape}\")\n",
    "print(export_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Resource Usage Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DuckDB memory usage statistics\n",
    "memory_stats = conn.execute(\"PRAGMA memory_limit\").fetchone()\n",
    "database_size = conn.execute(\"PRAGMA database_size\").fetchone()\n",
    "\n",
    "print(\"DuckDB Performance Summary:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Memory limit: {memory_stats[0]}\")\n",
    "print(f\"Database size: {database_size[0]}\")\n",
    "\n",
    "# Show system resource usage\n",
    "process = psutil.Process(os.getpid())\n",
    "memory_info = process.memory_info()\n",
    "cpu_percent = process.cpu_percent(interval=1)\n",
    "\n",
    "print(f\"\\nSystem Resource Usage:\")\n",
    "print(f\"Memory (RSS): {memory_info.rss / 1024 / 1024:.2f} MB\")\n",
    "print(f\"Memory (VMS): {memory_info.vms / 1024 / 1024:.2f} MB\")\n",
    "print(f\"CPU Usage: {cpu_percent:.1f}%\")\n",
    "\n",
    "print(\"\\n🎉 DuckDB exploration completed successfully!\")\n",
    "print(\"Ready to integrate with ClickHouse for distributed processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "conn.close()\n",
    "print(\"DuckDB connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}